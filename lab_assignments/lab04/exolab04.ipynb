{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExoStat Lab 04: Radial Velocity Method and Stellar Activity\n",
    "\n",
    "**Administrative details:**\n",
    "\n",
    "- This Lab will be turned in for credit.\n",
    "\n",
    "- Some questions of this lab are the same as the Practice 05 questions found on the main [YData website](http://ydata123.org/sp19/).  \n",
    "\n",
    "- Collaborating on the ExoStat Labs is encouraged. If you get stuck for a while on a question, feel free to ask a neighbor or come to the instructor's or TF's office hours for additional help. (Explaining things is beneficial, too -- the best way to solidify your knowledge of a subject is to explain it.) Please don't just share answers, though.\n",
    "\n",
    "This term we will be using Piazza for class discussion. Find our class page [here](https://piazza.com/yale/spring2019/sds170/home)\n",
    "\n",
    "You can read more about course policies on our [canvas site](https://canvas.yale.edu).\n",
    "\n",
    "**Deadline:**\n",
    "\n",
    "This assignment is due Monday, February 18th at 11:59 P.M. Late work will not be accepted as per the course policies (see the Syllabus and Course policies on [Canvas](https://canvas.yale.edu)).\n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the policies page to learn more about how to learn cooperatively.\n",
    "\n",
    "#### Today's ExoStat Lab\n",
    "\n",
    "1. [iteration and simulations](https://www.inferentialthinking.com/chapters/10/sampling-and-empirical-distributions.html)\n",
    "\n",
    "2. [randomness](https://www.inferentialthinking.com/chapters/09/randomness.html)\n",
    "\n",
    "The data used in these exercises contain salary data and other statistics for basketball players from the 2014-2015 NBA season. These data were collected from the following sports analytic sites: [Basketball Reference](http://www.basketball-reference.com) and [Spotrac](http://www.spotrac.com).\n",
    "\n",
    "3.  Fitting an RV curve\n",
    "\n",
    "4.  Sun spots\n",
    "\n",
    "**Submission:**\n",
    "\n",
    "Submit your assignment both as a .pdf and .ipynb (Jupyter notebook) in Canvas.  \n",
    "\n",
    "To produce the .pdf, please do the following in order to preserve the cell structure of the notebook:  \n",
    "1.  Go to \"File\" at the top-left of your Jupyter Notebook\n",
    "2.  Under \"Download as\", select \"HTML (.html)\"\n",
    "3.  After the .html has downloaded, open it and then select \"File\" and \"Print\" (note you will not actually be printing)\n",
    "4.  From the print window, select the option to save as a .pdf\n",
    "\n",
    "To produce the .ipynb, please do the following:  \n",
    "1.  Go to \"File\" at the top-left of your Jupyter Notebook\n",
    "2.  Under \"Download as\", select \"Notebook (.ipynb)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines import the Numpy and Datascience modules.\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Nachos and Conditionals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, Boolean values can either be `True` or `False`. We get Boolean values when using comparison operators such as `<` (less than), `>` (greater than), and `==` (equal to). A list of common comparison operators can be found below!\n",
    "\n",
    "<img src=\"comparisons.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to see an example of a comparison operator in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 > 1 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even assign the result of a comparison operation to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = 10 / 2 == 5\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays are compatible with comparison operators. The output is an array of boolean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_array(1, 5, 7, 8, 3, -1) > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One day, when you come home after a long week, you see a hot bowl of nachos waiting on the dining table! Let's say that whenever you take a nacho from the bowl, it will either have only **cheese**, only **salsa**, **both** cheese and salsa, or **neither** cheese nor salsa (a sad tortilla chip indeed). \n",
    "\n",
    "Let's try and simulate taking nachos from the bowl at random using the function, `np.random.choice(arr)`, where `arr` is the array that you're using. Start by running the cell below several times, and observe how the results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nachos = make_array('cheese', 'salsa', 'both', 'neither')\n",
    "np.random.choice(nachos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Assume we took ten nachos at random, and stored the results in an array called `ten_nachos` as done below. Find the number of nachos with only cheese using code (do not hardcode the answer).  \n",
    "\n",
    "*Hint:* Our solution involves a comparison operator and the `np.count_nonzero` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "ten_nachos = make_array('neither', 'cheese', 'both', 'both', 'cheese', 'salsa', 'both', 'neither', 'cheese', 'both')\n",
    "number_cheese = ...\n",
    "number_cheese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditional Statements**\n",
    "\n",
    "A conditional statement is composed of a sequence of conditions that allow Python to choose from different alternatives based on whether some condition is true.\n",
    "\n",
    "Here is a basic example.\n",
    "\n",
    "```\n",
    "def sign(x):\n",
    "    if x > 0:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "```\n",
    "\n",
    "If the input `x` is greater than `0`, we return the string `'Positive'`. Otherwise, we return `'Negative'`.\n",
    "\n",
    "If we want to test multiple conditions at once, we use the following general format.\n",
    "\n",
    "```\n",
    "if <if expression>:\n",
    "    <if body>\n",
    "elif <elif expression 0>:\n",
    "    <elif body 0>\n",
    "elif <elif expression 1>:\n",
    "    <elif body 1>\n",
    "...\n",
    "else:\n",
    "    <else body>\n",
    "```\n",
    "\n",
    "Only the body for which the conditional expression is true will be evaluated. Each `if` and `elif` expression is evaluated and considered in order, starting at the top. As soon as a true value is found, the corresponding body is executed, and the rest of the conditional statement is skipped. If none of the `if` or `elif` expressions are true, then the `else body` is executed. \n",
    "\n",
    "For more examples and explanation, refer to the section on conditional statements [here](https://www.inferentialthinking.com/chapters/09/1/conditional-statements.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Complete the following conditional statement so that the string `'More please'` is assigned to the variable `say_please` if the number of nachos with cheese in `ten_nachos` is less than `5`.\n",
    "\n",
    "*Hint*: You should not have to directly reference the variable `ten_nachos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "say_please = '?'\n",
    "\n",
    "if ...:\n",
    "    say_please = 'More please'\n",
    "    \n",
    "say_please"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Write a function called `nacho_reaction` that returns a string based on the type of nacho passed in as an argument. From top to bottom, the conditions should correspond to: `'cheese'`, `'salsa'`, `'both'`, `'neither'`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def nacho_reaction(nacho):\n",
    "    if ...:\n",
    "        return 'Cheesy!'\n",
    "    # next condition should return 'Spicy!'\n",
    "    ...\n",
    "    # next condition should return 'Wow!'\n",
    "    ...\n",
    "    # next condition should return 'Meh.'\n",
    "    ...\n",
    "\n",
    "spicy_nacho = nacho_reaction('salsa')\n",
    "spicy_nacho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** Add a column `'Reactions'` to the table `ten_nachos_reactions` that consists of reactions for each of the nachos in `ten_nachos`. \n",
    "\n",
    "*Hint:* Use the `apply` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "ten_nachos_reactions = Table().with_column('Nachos', ten_nachos)\n",
    "...\n",
    "ten_nachos_reactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Using code, find the number of `'Wow!'` reactions for the nachos in `ten_nachos_reactions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "number_wow_reactions = ...\n",
    "number_wow_reactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simulations and For Loops\n",
    "Using a `for` statement, we can perform a task multiple times. This is known as iteration. Here, we'll simulate drawing different suits from a deck of cards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"♡\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suits = make_array(\"♤\", \"♡\", \"♢\", \"♧\")\n",
    "\n",
    "draws = make_array()\n",
    "\n",
    "repetitions = 6\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    draws = np.append(draws, np.random.choice(suits))\n",
    "\n",
    "draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unrolled version of this `for` loop can be found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draws = make_array()\n",
    "\n",
    "draws = np.append(draws, np.random.choice(suits))\n",
    "draws = np.append(draws, np.random.choice(suits))\n",
    "draws = np.append(draws, np.random.choice(suits))\n",
    "draws = np.append(draws, np.random.choice(suits))\n",
    "draws = np.append(draws, np.random.choice(suits))\n",
    "draws = np.append(draws, np.random.choice(suits))\n",
    "\n",
    "draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, the `for` loop appends a random draw to the `draws` array for every number in `np.arange(repetitions)`. \n",
    "\n",
    "Here's a nice way to think of what we did above. We had a deck of 4 cards of different suits, we randomly drew one card, saw the suit, kept track of it in `draws`, and put the card back into the deck. We repeated this for a total of 6 times without having to repeat code, thanks to the `for` loop. We simulated this experiment using a `for` loop. \n",
    "\n",
    "Another use of iteration is to loop through a set of values. For instance, we can print out all of the colors of the rainbow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainbow = make_array(\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"indigo\", \"violet\")\n",
    "\n",
    "for color in rainbow:\n",
    "    print(color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the indented part of the `for` loop, known as the body, is executed once for each item in `rainbow`. Note that the name `color` is arbitrary; we could easily have named it something else. The important thing is we stay consistent throughout the `for` loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for another_name in rainbow:\n",
    "    print(another_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, however, we would like the variable name to be somewhat informative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Clay is playing darts. His dartboard contains ten equal-sized zones with point values from 1 to 10. Write code that simulates his total score after 1000 dart tosses. Make sure to use a `for` loop.\n",
    "\n",
    "*Hint:* There are a few steps to this problem (and most simulations): \n",
    "1. Figuring out the big picture of what we want to simulate (the total score after 1000 dart tosses)\n",
    "2. Deciding the possible values you can take in the experiment (point values in this case) and simulating one example (throwing one dart)\n",
    "3. Deciding how many times to run through the experiment (1000 tosses in our case) and keeping track of the total information of each time you ran through the experiment (the total score in this case)\n",
    "4. Coding up the whole simulation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "possible_point_values = ...\n",
    "tosses = 1000\n",
    "total_score = ...\n",
    "\n",
    "# a for loop would be useful here\n",
    "\n",
    "\n",
    "\n",
    "total_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** In the following cell, we've loaded the text of _Pride and Prejudice_ by Jane Austen, split it into individual words, and stored these words in an array. Using a `for` loop, assign `longer_than_five` to the number of words in the novel that are more than 5 letters long.\n",
    "\n",
    "*Hint*: You can find the number of letters in a word with the `len` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "austen_string = open('Austen_PrideAndPrejudice.txt', encoding='utf-8').read()\n",
    "p_and_p_words = np.array(austen_string.split())\n",
    "\n",
    "longer_than_five = ...\n",
    "\n",
    "# a for loop would be useful here\n",
    "\n",
    "\n",
    "longer_than_five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Using simulation with 10,000 trials, assign `chance_of_all_different` to an estimate of the chance that if you pick three words from Pride and Prejudice uniformly at random (with replacement), they all have different lengths. \n",
    "\n",
    "*Hint*: Remember that `!=` only checks for non-equality between two items, not three. Try using `and`, e.g., `3 != 2 and 2 != 4` will be `True`, but `7 > 0 and 0 == 1` will be `False)\n",
    "\n",
    "For example, `2 != 3 != 4` first checks for non-equality between `2` and `3`, then `3` and `4`, but NOT `2` and `4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "trials = 10000\n",
    "different = ...\n",
    "\n",
    "for ... in ...:\n",
    "    ...\n",
    "\n",
    "chance_of_all_different = ...\n",
    "\n",
    "chance_of_all_different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sampling Basketball Data\n",
    "\n",
    "Run the cell below to load the player and salary data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_data = Table().read_table(\"player_data.csv\")\n",
    "salary_data = Table().read_table(\"salary_data.csv\")\n",
    "full_data = salary_data.join(\"PlayerName\", player_data, \"Name\")\n",
    "# The show method immediately displays the contents of a table. \n",
    "# This way, we can display the top of two tables using a single cell.\n",
    "player_data.show(3)\n",
    "salary_data.show(3)\n",
    "full_data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than getting data on every player, imagine that we had gotten data on only a smaller subset of the players.  For 492 players, it's not so unreasonable to expect to see all the data, but usually we aren't so lucky.  Instead, we often make *statistical inferences* about a large underlying population using a smaller sample.\n",
    "\n",
    "A statistical inference is a statement about some statistic of the underlying population, such as \"the average salary of NBA players in 2014 was $3\".  You may have heard the word \"inference\" used in other contexts.  It's important to keep in mind that statistical inferences, unlike, say, logical inferences, can be wrong.\n",
    "\n",
    "A general strategy for inference using samples is to estimate statistics of the population by computing the same statistics on a sample.  This strategy sometimes works well and sometimes doesn't.  The degree to which it gives us useful answers depends on several factors, and we'll touch lightly on a few of those today.\n",
    "\n",
    "One very important factor in the utility of samples is how they were gathered.  We have prepared some example sample datasets to simulate inference from different kinds of samples for the NBA player dataset.  Later we'll ask you to create your own samples to see how they behave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save typing and increase the clarity of your code, we will package the loading and analysis code into two functions. This will be useful in the rest of the exercises as we will repeatedly need to create histograms and collect summary statistics from that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1**. Complete the `histograms` function, which takes a table with columns `Age` and `Salary` and draws a histogram for each one. Use the min and max functions to pick the bin boundaries so that all data appears for any table passed to your function. Use the same bin widths as before (1 year for `Age` and $1,000,000 for `Salary`).\n",
    "\n",
    "*Hint*: When creating the bins for the the histograms, think critically about what the stop argument should be for `np.arange`. Histograms are inclusive on the left hand side of the interval, but not the right. So, if we have a maximum age of 80, we need a 80-81 bin in order to capture this in the histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def histograms(t):\n",
    "    ages = t.column('Age')\n",
    "    salaries = t.column('Salary')\n",
    "    age_bins = ...\n",
    "    salary_bins = ...\n",
    "    t.hist('Age', bins=age_bins, unit='year')\n",
    "    t.hist('Salary', bins=salary_bins, unit='$')\n",
    "    return age_bins # Keep this statement so that your work can be checked\n",
    "    \n",
    "histograms(full_data)\n",
    "print('Two histograms should be displayed below')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2**. Create a function called `compute_statistics` that takes a Table containing ages and salaries and:\n",
    "- Draws a histogram of ages\n",
    "- Draws a histogram of salaries\n",
    "- Returns a two-element array containing the average age and average salary\n",
    "\n",
    "You can call your `histograms` function to draw the histograms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def compute_statistics(age_and_salary_data):\n",
    "    ...\n",
    "    age = ...\n",
    "    salary = ...\n",
    "    ...\n",
    "    \n",
    "\n",
    "full_stats = compute_statistics(full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convenience sampling\n",
    "One sampling methodology, which is **generally a bad idea**, is to choose players who are somehow convenient to sample.  For example, you might choose players from one team that's near your house, since it's easier to survey them.  This is called, somewhat pejoratively, *convenience sampling*.\n",
    "\n",
    "Suppose you survey only *relatively new* players with ages less than 22.  (The more experienced players didn't bother to answer your surveys about their salaries.)\n",
    "\n",
    "**Question 3.3**  Assign `convenience_sample_data` to a subset of `full_data` that contains only the rows for players under the age of 22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "convenience_sample = ...\n",
    "convenience_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4** Assign `convenience_stats` to a list of the average age and average salary of your convenience sample, using the `compute_statistics` function.  Since they're computed on a sample, these are called *sample averages*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "convenience_stats = ...\n",
    "convenience_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll compare the convenience sample salaries with the full data salaries in a single histogram. To do that, we'll need to use the `bin_column` option of the `hist` method, which indicates that all columns are counts of the bins in a particular column. The following cell should not require any changes; just run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_salaries(first, second, first_title, second_title):\n",
    "    \"\"\"Compare the salaries in two tables.\"\"\"\n",
    "    max_salary = max(np.append(first.column('Salary'), second.column('Salary')))\n",
    "    bins = np.arange(0, max_salary+1e6+1, 1e6)\n",
    "    first_binned = first.bin('Salary', bins=bins).relabeled(1, first_title)\n",
    "    second_binned = second.bin('Salary', bins=bins).relabeled(1, second_title)\n",
    "    first_binned.join('bin', second_binned).hist(bin_column='bin')\n",
    "\n",
    "compare_salaries(full_data, convenience_sample, 'All Players', 'Convenience Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5** Does the convenience sample give us an accurate picture of the age and salary of the full population of NBA players in 2014-2015?  Would you expect it to, in general?  Before you move on, write a short answer in English below.  You can refer to the statistics calculated above or perform your own analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_problem_id": "convenience_3_5"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple random sampling\n",
    "A more principled approach is to sample uniformly at random from the players.  If we ensure that each player is selected at most once, this is a *simple random sample without replacement*, sometimes abbreviated to \"simple random sample\" or \"SRSWOR\".  Imagine writing down each player's name on a card, putting the cards in an urn, and shuffling the urn.  Then, pull out cards one by one and set them aside, stopping when the specified *sample size* is reached.\n",
    "\n",
    "We've produced two samples of the `salary_data` table in this way: `small_srswor_salary.csv` and `large_srswor_salary.csv` contain, respectively, a sample of size 44 (the same as the convenience sample) and a larger sample of size 100.  \n",
    "\n",
    "The `load_data` function below loads a salary table and joins it with `player_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(salary_file):\n",
    "    return player_data.join('Name', Table.read_table(salary_file), 'PlayerName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6** Run the same analyses on the small and large samples that you previously ran on the full dataset and on the convenience sample.  Which is more accurate, the estimate of population statistics that we get from the convenience sample, the estimate from the small simple random sample, or the estimate from the large simple random sample?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Original:\n",
    "small_srswor_data = ...\n",
    "small_stats = ...\n",
    "large_srswor_data = ...\n",
    "large_stats = ...\n",
    "print('Full data stats:                 ', full_stats)\n",
    "print('Small simple random sample stats:', small_stats)\n",
    "print('Large simple random sample stats:', large_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing simple random samples\n",
    "Often it's useful to take random samples even when we have a larger dataset available. Another is to help us understand how inaccurate other samples are.\n",
    "\n",
    "Tables provide the method `sample()` for producing random samples.  Note that its default is to sample with replacement. To see how to call `sample()`, search the documentation on the [datascience documentation](http://data8.org/datascience/) of the course website, or enter `full_data.sample?` into a code cell and press Shift + Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7** Produce a simple random sample of size 44 from `full_data`.  (You don't need to bother with a join this time -- just use `full_data.sample(...)` directly.  That will have the same result as sampling from `salary_data` and joining with `player_data`.)  Run your analysis on it again.  \n",
    "- Are your results roughly similar to those in the small sample we provided you?  Run your code several times to get new samples.  \n",
    "- How much does the average age change across samples? \n",
    "- What about average salary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_small_srswor_data = ...\n",
    "my_small_stats = ...\n",
    "my_small_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_problem_id": "q_3_7_samples"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8** As in the previous question, analyze several simple random samples of size 100 from `full_data`.  \n",
    "- Do the histogram statistics seem to change more or less across samples of 100 than across samples of size 44?  \n",
    "- Are the sample averages and histograms closer to their true values for age or for salary?  What did you expect to see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_large_srswor_data = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_problem_id": "large_srs_q"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Radial Velocity Light Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by looking at what we did last week with the 51 Pegasi dataset.  Recall that [51 Pegasi b](https://en.wikipedia.org/wiki/51_Pegasi_b) was the first exoplanet (in 1995) to be discovered orbiting a Sun-like star.\n",
    "\n",
    "We are going to import some new modules, which we will be using later in order to fit an RV curve to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as sig\n",
    "from scipy.optimize import curve_fit,fsolve\n",
    "from rv import *\n",
    "from rv_fit import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to read-in the 51 Pegasi data, `51peg.dat`, using a special function from the `rv` module.  The `rv` module defines a variable, `star`, which contains some useful information about the host star.  Below we look at some of those properties after loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star= load_single_star(\"51peg.dat\") \n",
    "\n",
    "print(\"Star name:\", star.name)\n",
    "print(\"Star mass:\", star.mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1.** The `star` also contains the time information in `star.t` and the radial velocity information in `star.vr`.  Use this information to make a scatter plot of the RV data.  Be sure to add axis labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week we used a default sinusoid model with known parameters (we assumed we knew the mass of the planet was 0.472 $M_J$ and the orbital period was 4.230785 days).  This week we are going to actually fit the model without assuming we know those parameters.\n",
    "\n",
    "We will be using the noted `rv` and `rv_fit` modules.  More information about the modules can be found in [this tutorial](http://adamdempsey90.github.io/python/radial_velocities/radial_velocities.html).\n",
    "\n",
    "All the hard work is going on in the background of the `fit_function` function that we use below.  The first input is the `star` information, and the second argument is the function we are using to fit the data, `fitting_function`.\n",
    "\n",
    "When you run the cell below, you will see the parameter estimates for the mass of the planet (`Mp`), the eccentricity (`e`), the orbital period (`P`), and the semi-major axis (`a`), along with their uncertainties.  If you compare these values to the estimates in the table found [here](https://en.wikipedia.org/wiki/51_Pegasi), you will notice the values are different...but not too far off.  We are not using the full dataset for our modeling, and different methods will also result in different estimates.\n",
    "\n",
    "As you scroll down and look at the output, you will see a periodogram.  This was used to get an estimate of the orbital period.  And the plot below the periodogram shows the observations (with their error bars) along with the model fit.  Below that is a plot of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = fit_data(star,fitting_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `model_fit` output is a dictionary.  The dictionary key can be displayed by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the output value for `Mp`, you can run the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit[\"Mp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `\"Mp\"` can be changed to any of the other keys to get their corresponding estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2.** Make a scatterplot of the fit model using `t_fit` on the horizontal axis and `vr_fit` on the vertical axis.  Be sure to add axis labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3.** Now let's look at a new star.  Read in the `hd10442.dat` and print out the star name and mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4.** Make a scatterplot of the time and RV data.  Be sure to add axis labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.5.**  Fit the RV curve model to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.6.**  What is the estimated mass, eccentricity, and orbital period of the exoplanet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mass = ...\n",
    "\n",
    "Eccentricity = ...\n",
    "\n",
    "Orbital period = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.7.** Make a scatterplot of the fit model using `t_fit` on the horizontal axis and `vr_fit` on the vertical axis.  Be sure to add axis labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.  Sunspot data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to explore the activity level of our very own Sun by considering the number of [Sunspots](https://en.wikipedia.org/wiki/Sunspot) each year as a proxy for the activity level of that year.  The data were pulled from the textbook [Bayesian Models for Astrophysical Data](https://www.cambridge.org/core/books/bayesian-models-for-astrophysical-data/A521B3BB3A2E1621EE1B907E87207218)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.1.**  Load the Sunspot dataset, `sunspot.csv`, into your notebook and plot the number of spots, `nspot`, versus `year`. Make the plot so that the data are plotted as a scatterplot and as a line. \n",
    "Hint:  consider using the `plots.scatter` and `plots.plot`.\n",
    "Make the scatterplot points green by adding the `color = \"green\"` argument.  You may want to decrease the thickness of the line using the argument `linewidth = .5`.\n",
    "Do you notice any general patterns or trends? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Note any trends here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.2.**  What was the first and last year of observation?  What is the frequency of the observations?  That is, how much time between each observation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.3.**  What is the distribution of the number of spots across the time period of the data?  This can be answered by making a histogram.  Set the bins to go from 0 to 275 with widths of 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.4.**  What percentage of spot numbers are greater than 200?  Answer this both with programming and with a hard-coded calculation by looking at the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questionn 5.5.** In a YData lecture demo, we developed a function for predicting a child's height by the average of the parents height using a dataset with observations on these quantities.  \n",
    "(See the class demo from the lecture on 2/4 (functions) [here](http://ydata123.org/sp19/calendar.html).)\n",
    "\n",
    "We are going to use a similar function for a spot data, except instead of using it for prediction, we are going to use it to get local averages of the data, which would allow us to search for any longer scale trends.\n",
    "\n",
    "Below is the start of a function, `smooth_spot`, that almost does  what we want...it takes a year as the input, then looks at the two years surrounding that year and calculates and average of the `nspots` within that window.  Update the function so that it takes a second variable, `year_width` with a default value of `2`, but allows us to change the width of the interval to any desired size.  Be sure to test your function to make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust this code\n",
    "def smooth_spot(year):\n",
    "    nearby = spots.where('year', are.between(year-2, year+2))\n",
    "    return nearby.column('nspots').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.6.**  Now that you have defined the function apply the function to our data and call the output `spots_model_2` using the `year_width = 2`.  Repeat this for `year_width = 10`, call the output `spots_model_10`.  Add both as columna to the `spots` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.7.**  Now make a scatterplot with the data points and both `spots_model_2` and `spots_model_10` included as lines.  What is the difference between the two models?  Explain why this difference happens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Explain here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission:** Once you're finished, follow the instructions at the top of this notebook to save as a .pdf and .ipynb.  Then submit the two files through Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
